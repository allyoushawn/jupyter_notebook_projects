{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyO0Z1XWFEdz+Uo+yt72UTSW",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/allyoushawn/jupyter_notebook_projects/blob/main/ml_misc/mtl_implementation.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "_jevuS7L2kGp"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "\n",
        "# Expert Network\n",
        "class Expert(nn.Module):\n",
        "    def __init__(self, input_dim, hidden_dim):\n",
        "        super().__init__()\n",
        "        self.fc = nn.Sequential(\n",
        "            nn.Linear(input_dim, hidden_dim),\n",
        "            nn.ReLU()\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.fc(x)\n",
        "\n",
        "# Multi-gate Mixture-of-Experts\n",
        "class MMoE(nn.Module):\n",
        "    def __init__(self, input_dim, num_experts, expert_hidden, num_tasks, tower_hidden, output_dims):\n",
        "        super().__init__()\n",
        "        self.num_experts = num_experts\n",
        "        self.num_tasks = num_tasks\n",
        "\n",
        "        # Shared experts\n",
        "        self.experts = nn.ModuleList([Expert(input_dim, expert_hidden) for _ in range(num_experts)])\n",
        "\n",
        "        # Task-specific gates\n",
        "        self.gates = nn.ModuleList([nn.Linear(input_dim, num_experts) for _ in range(num_tasks)])\n",
        "\n",
        "        # Task-specific towers\n",
        "        self.towers = nn.ModuleList([\n",
        "            nn.Sequential(\n",
        "                nn.Linear(expert_hidden, tower_hidden),\n",
        "                nn.ReLU(),\n",
        "                nn.Linear(tower_hidden, output_dims[i])\n",
        "            ) for i in range(num_tasks)\n",
        "        ])\n",
        "\n",
        "    def forward(self, x):\n",
        "        # Get expert outputs\n",
        "        expert_outputs = torch.stack([expert(x) for expert in self.experts], dim=2)  # [B, H, E]\n",
        "        # [B, H, E] â†’ [B, E, H]\n",
        "        expert_outputs = expert_outputs.permute(0, 2, 1)\n",
        "\n",
        "        task_outputs = []\n",
        "        for t in range(self.num_tasks):\n",
        "            # Compute task-specific gating weights\n",
        "            gate_scores = F.softmax(self.gates[t](x), dim=1).unsqueeze(1)  # [B, 1, E]\n",
        "\n",
        "            # Weighted sum of expert outputs\n",
        "            mixed_expert_output = torch.bmm(gate_scores, expert_outputs).squeeze(1)  # [B, H]\n",
        "\n",
        "            # Pass through task-specific tower\n",
        "            out = self.towers[t](mixed_expert_output)\n",
        "            task_outputs.append(out)\n",
        "\n",
        "        return task_outputs\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Suppose we have 2 tasks: Task A (binary classification), Task B (multi-class)\n",
        "input_dim = 20\n",
        "num_experts = 4\n",
        "expert_hidden = 64\n",
        "num_tasks = 2\n",
        "tower_hidden = 32\n",
        "output_dims = [2, 3]  # Task A has 2 classes, Task B has 3 classes\n",
        "\n",
        "model = MMoE(input_dim, num_experts, expert_hidden, num_tasks, tower_hidden, output_dims)\n",
        "\n",
        "# Example input\n",
        "x = torch.randn(5, input_dim)  # batch size 5\n",
        "task_outputs = model(x)\n",
        "\n",
        "print(\"Task A output:\", task_outputs[0].shape)  # [5, 2]\n",
        "print(\"Task B output:\", task_outputs[1].shape)  # [5, 3]\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fM3vnfnB3J2J",
        "outputId": "373cbd97-3699-4aeb-c6f9-8041f47cea03"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Task A output: torch.Size([5, 2])\n",
            "Task B output: torch.Size([5, 3])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "optimizer = torch.optim.Adam(model.parameters(), lr=1e-3)\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "# Fake labels\n",
        "y_taskA = torch.randint(0, 2, (5,))\n",
        "y_taskB = torch.randint(0, 3, (5,))\n",
        "\n",
        "# Forward\n",
        "out_taskA, out_taskB = model(x)\n",
        "\n",
        "# Compute losses\n",
        "lossA = criterion(out_taskA, y_taskA)\n",
        "lossB = criterion(out_taskB, y_taskB)\n",
        "loss = lossA + lossB\n",
        "\n",
        "# Backward\n",
        "optimizer.zero_grad()\n",
        "loss.backward()\n",
        "optimizer.step()\n",
        "\n",
        "print(f\"LossA={lossA.item():.4f}, LossB={lossB.item():.4f}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8jeET9Ij3Pki",
        "outputId": "a6153a65-46a0-48fc-b958-fa0fe13019ba"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "LossA=0.6912, LossB=1.1325\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "def count_parameters(model):\n",
        "    return sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
        "\n",
        "# ------------------------\n",
        "# 1. Synthetic Dataset\n",
        "# ------------------------\n",
        "np.random.seed(42)\n",
        "torch.manual_seed(42)\n",
        "\n",
        "\n",
        "n_samples = 20000\n",
        "n_train = 15000\n",
        "X = np.linspace(-2*np.pi, 2*np.pi, n_samples).reshape(-1, 1)\n",
        "y1 = np.sin(X) + 0.1 * np.random.randn(*X.shape)\n",
        "y2 = np.cos(X) + 0.1 * np.random.randn(*X.shape)\n",
        "\n",
        "X_train, X_test = torch.tensor(X[:n_train], dtype=torch.float32), torch.tensor(X[n_train:], dtype=torch.float32)\n",
        "y1_train, y1_test = torch.tensor(y1[:n_train], dtype=torch.float32), torch.tensor(y1[n_train:], dtype=torch.float32)\n",
        "y2_train, y2_test = torch.tensor(y2[:n_train], dtype=torch.float32), torch.tensor(y2[n_train:], dtype=torch.float32)\n",
        "\n",
        "# ------------------------\n",
        "# 2. Model Definitions\n",
        "# ------------------------\n",
        "class SharedBottom(nn.Module):\n",
        "    def __init__(self, input_dim, shared_hidden, task_hidden):\n",
        "        super().__init__()\n",
        "        self.shared = nn.Sequential(\n",
        "            nn.Linear(input_dim, shared_hidden),\n",
        "            nn.ReLU()\n",
        "        )\n",
        "        self.task1 = nn.Sequential(\n",
        "            nn.Linear(shared_hidden, task_hidden),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(task_hidden, 1)\n",
        "        )\n",
        "        self.task2 = nn.Sequential(\n",
        "            nn.Linear(shared_hidden, task_hidden),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(task_hidden, 1)\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        shared_out = self.shared(x)\n",
        "        return self.task1(shared_out), self.task2(shared_out)\n",
        "\n",
        "class Expert(nn.Module):\n",
        "    def __init__(self, input_dim, hidden_dim):\n",
        "        super().__init__()\n",
        "        self.fc = nn.Sequential(\n",
        "            nn.Linear(input_dim, hidden_dim),\n",
        "            nn.ReLU()\n",
        "        )\n",
        "    def forward(self, x):\n",
        "        return self.fc(x)\n",
        "\n",
        "class MMoE(nn.Module):\n",
        "    def __init__(self, input_dim, num_experts, expert_hidden, num_tasks, tower_hidden):\n",
        "        super().__init__()\n",
        "        self.experts = nn.ModuleList([Expert(input_dim, expert_hidden) for _ in range(num_experts)])\n",
        "        self.gates = nn.ModuleList([nn.Linear(input_dim, num_experts) for _ in range(num_tasks)])\n",
        "        self.towers = nn.ModuleList([\n",
        "            nn.Sequential(\n",
        "                nn.Linear(expert_hidden, tower_hidden),\n",
        "                nn.ReLU(),\n",
        "                nn.Linear(tower_hidden, 1)\n",
        "            ) for _ in range(num_tasks)\n",
        "        ])\n",
        "\n",
        "    def forward(self, x):\n",
        "        expert_outputs = torch.stack([expert(x) for expert in self.experts], dim=2)  # [B,H,E]\n",
        "        expert_outputs = expert_outputs.permute(0, 2, 1)  # [B,E,H]\n",
        "        task_outputs = []\n",
        "        for t in range(len(self.towers)):\n",
        "            gate_scores = F.softmax(self.gates[t](x), dim=1).unsqueeze(1)  # [B,1,E]\n",
        "            mixed_expert_output = torch.bmm(gate_scores, expert_outputs).squeeze(1)  # [B,H]\n",
        "            out = self.towers[t](mixed_expert_output)\n",
        "            task_outputs.append(out)\n",
        "        return task_outputs\n",
        "\n",
        "\n",
        "\n",
        "# PLE block (1 layer of shared + task-specific experts)\n",
        "class PLELayer(nn.Module):\n",
        "    def __init__(self, input_dim, expert_hidden, num_shared, num_task_specific, num_tasks):\n",
        "        super().__init__()\n",
        "        self.num_tasks = num_tasks\n",
        "        # Shared experts\n",
        "        self.shared_experts = nn.ModuleList([Expert(input_dim, expert_hidden) for _ in range(num_shared)])\n",
        "        # Task-specific experts\n",
        "        self.task_experts = nn.ModuleList([\n",
        "            nn.ModuleList([Expert(input_dim, expert_hidden) for _ in range(num_task_specific)])\n",
        "            for _ in range(num_tasks)\n",
        "        ])\n",
        "        # Gates\n",
        "        self.task_gates = nn.ModuleList([nn.Linear(input_dim, num_shared + num_task_specific) for _ in range(num_tasks)])\n",
        "        self.shared_gate = nn.Linear(input_dim, num_shared + num_task_specific * num_tasks)\n",
        "\n",
        "    def forward(self, x):\n",
        "        shared_outputs = [e(x) for e in self.shared_experts]  # list of [B,H]\n",
        "        task_outputs = [[e(x) for e in experts] for experts in self.task_experts]  # list(task)[list(experts)]\n",
        "\n",
        "        # Combine into matrices\n",
        "        shared_tensor = torch.stack(shared_outputs, dim=1)  # [B, num_shared, H]\n",
        "        task_tensors = [torch.stack(exps, dim=1) for exps in task_outputs]  # each: [B, num_task_specific, H]\n",
        "\n",
        "        # Shared gate input = all experts\n",
        "        all_experts = torch.cat([shared_tensor] + task_tensors, dim=1)  # [B, num_shared+Î£ num_task_specific, H]\n",
        "        shared_gate_scores = F.softmax(self.shared_gate(x), dim=1).unsqueeze(1)  # [B,1,E_all]\n",
        "        shared_mix = torch.bmm(shared_gate_scores, all_experts).squeeze(1)  # [B,H]\n",
        "\n",
        "        # Task-specific mixtures\n",
        "        task_mixes = []\n",
        "        for t in range(self.num_tasks):\n",
        "            expert_pool = torch.cat([shared_tensor, task_tensors[t]], dim=1)  # [B,num_shared+num_task_specific,H]\n",
        "            gate_scores = F.softmax(self.task_gates[t](x), dim=1).unsqueeze(1)  # [B,1,E_task+shared]\n",
        "            mix = torch.bmm(gate_scores, expert_pool).squeeze(1)  # [B,H]\n",
        "            task_mixes.append(mix)\n",
        "\n",
        "        return shared_mix, task_mixes\n",
        "\n",
        "# Full PLE model\n",
        "class PLE(nn.Module):\n",
        "    def __init__(self, input_dim, expert_hidden, num_shared, num_task_specific, num_tasks, tower_hidden):\n",
        "        super().__init__()\n",
        "        self.layer = PLELayer(input_dim, expert_hidden, num_shared, num_task_specific, num_tasks)\n",
        "        self.towers = nn.ModuleList([\n",
        "            nn.Sequential(\n",
        "                nn.Linear(expert_hidden, tower_hidden),\n",
        "                nn.ReLU(),\n",
        "                nn.Linear(tower_hidden, 1)\n",
        "            ) for _ in range(num_tasks)\n",
        "        ])\n",
        "\n",
        "    def forward(self, x):\n",
        "        shared_mix, task_mixes = self.layer(x)\n",
        "        outputs = [tower(task_mixes[t]) for t, tower in enumerate(self.towers)]\n",
        "        return outputs\n",
        "\n",
        "\n",
        "# ------------------------\n",
        "# 3. Training Utility\n",
        "# ------------------------\n",
        "def train_model(model, X_train, y1_train, y2_train, epochs=100, lr=1e-3):\n",
        "    optimizer = optim.Adam(model.parameters(), lr=lr)\n",
        "    criterion = nn.MSELoss()\n",
        "    for epoch in range(epochs):\n",
        "        model.train()\n",
        "        out1, out2 = model(X_train)\n",
        "        loss1 = criterion(out1, y1_train)\n",
        "        loss2 = criterion(out2, y2_train)\n",
        "        loss = loss1 + loss2\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        if (epoch+1) % 20 == 0:\n",
        "            print(f\"Epoch {epoch+1}, Loss1={loss1.item():.4f}, Loss2={loss2.item():.4f}\")\n",
        "    return model\n",
        "\n",
        "def evaluate_model(model, X_test, y1_test, y2_test):\n",
        "    model.eval()\n",
        "    with torch.no_grad():\n",
        "        out1, out2 = model(X_test)\n",
        "        mse1 = F.mse_loss(out1, y1_test).item()\n",
        "        mse2 = F.mse_loss(out2, y2_test).item()\n",
        "    return mse1, mse2\n",
        "\n",
        "# ------------------------\n",
        "# 4. Run Comparisons\n",
        "# ------------------------\n",
        "shared_model = SharedBottom(input_dim=1, shared_hidden=32, task_hidden=16)\n",
        "mmoe_model = MMoE(input_dim=1, num_experts=10, expert_hidden=16, num_tasks=2, tower_hidden=16)\n",
        "ple_model = PLE(input_dim=1, expert_hidden=16,\n",
        "                num_shared=4, num_task_specific=2,\n",
        "                num_tasks=2, tower_hidden=16)\n",
        "\n",
        "print(\"SharedBottom params:\", count_parameters(shared_model))\n",
        "print(\"MMoE params:\", count_parameters(mmoe_model))\n",
        "print(\"PLE params:\", count_parameters(ple_model))\n",
        "\n",
        "print(\"\\nTraining PLE...\")\n",
        "train_model(ple_model, X_train, y1_train, y2_train)\n",
        "\n",
        "\n",
        "print(\"\\nTraining SharedBottom...\")\n",
        "train_model(shared_model, X_train, y1_train, y2_train)\n",
        "\n",
        "print(\"\\nTraining MMoE...\")\n",
        "train_model(mmoe_model, X_train, y1_train, y2_train)\n",
        "\n",
        "mse_ple = evaluate_model(ple_model, X_test, y1_test, y2_test)\n",
        "mse_shared = evaluate_model(shared_model, X_test, y1_test, y2_test)\n",
        "mse_mmoe = evaluate_model(mmoe_model, X_test, y1_test, y2_test)\n",
        "\n",
        "print(\"\\nTest MSEs:\")\n",
        "print(\"PLE:\", mse_ple)\n",
        "print(\"SharedBottom:\", mse_shared)\n",
        "print(\"MMoE:\", mse_mmoe)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zGjyok_V3Yst",
        "outputId": "793106ad-b82a-4ce9-c687-1b703fa51c12"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "SharedBottom params: 1154\n",
            "MMoE params: 938\n",
            "PLE params: 874\n",
            "\n",
            "Training PLE...\n",
            "Epoch 20, Loss1=0.4471, Loss2=0.5027\n",
            "Epoch 40, Loss1=0.3881, Loss2=0.4670\n",
            "Epoch 60, Loss1=0.3521, Loss2=0.4307\n",
            "Epoch 80, Loss1=0.3146, Loss2=0.3915\n",
            "Epoch 100, Loss1=0.2714, Loss2=0.3435\n",
            "\n",
            "Training SharedBottom...\n",
            "Epoch 20, Loss1=0.4227, Loss2=0.4779\n",
            "Epoch 40, Loss1=0.3448, Loss2=0.4380\n",
            "Epoch 60, Loss1=0.2759, Loss2=0.3990\n",
            "Epoch 80, Loss1=0.2105, Loss2=0.3500\n",
            "Epoch 100, Loss1=0.1600, Loss2=0.2927\n",
            "\n",
            "Training MMoE...\n",
            "Epoch 20, Loss1=0.3919, Loss2=0.4681\n",
            "Epoch 40, Loss1=0.3522, Loss2=0.4296\n",
            "Epoch 60, Loss1=0.3097, Loss2=0.3805\n",
            "Epoch 80, Loss1=0.2536, Loss2=0.3149\n",
            "Epoch 100, Loss1=0.1962, Loss2=0.2334\n",
            "\n",
            "Test MSEs:\n",
            "PLE: (2.031019926071167, 2.62198805809021)\n",
            "SharedBottom: (3.1019022464752197, 3.557650089263916)\n",
            "MMoE: (1.8900976181030273, 3.7187914848327637)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "H8r_bTwT_VGV"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}